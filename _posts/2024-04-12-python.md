---
layout: post
title:  "AI Model Train"
---


## 학습 데이터 준비 

## Solar 모델에서 학습 
<span style='background-color:#f5f0ff'>Solar</span> <br>
Depth Upscaling (깊이 업스케일링 : DUS ) : 대규모 언어 모델을 확장하기 위한 기술로 모델의 깊이를 증가시킨다. 
언어 모델의 깊이는 모델이 가지는 층(layers) 의 수를 의미한다 => 모델의 표현력과 성능을 향상 시킬 수 있다. 
여기서 층(layers)는 데이터를 처리하고 특정 유형의 연산을 수행하는 단위입니다. 

트랜스포머모델의 각 레이어는 3가지로 구성됩니다. 
1. <b>Self-Attention Mechanism</b> <br>
   

## <span style='background-color:#f0f5ff'>DPO</span> 
<span style='background-color:#f5f0ff'>DPO</span> 는 Directly Preference Optimization 이다. 
두 모델 간의 대답 분포도를 비교하여 사용자가 원하는 대답으로 분포를 맞춰주는 방법.

## 학습 과정 
## => ```os.walk``` 를 사용하여 튜플객체를 만들고 , 
## => ```endswith```를 사용하여 json 확장자 파일만 추출하고 
## => ```append```를 사용하여 file_list에 파일명을 저장해 , 이때  ```join```를 사용하여 폴더명과 파일명을 연결하여 만들어서 file_list에 파일명을 저장해 
```
### json 학습 데이터를 가져와서 리스트에 담기 
import os

data_path = '/home/min/llm/AI_Correct/essay_scoring_data/'

for i in os.walk(data_path):
    print(i)

```
## 튜플 - 여러값을 반환할 때 유용하다. 그런데, 튜플의 요소는 생성 후 변경이 어렵고, 특정 순서가 있다. 다양한 데이터 타입을 함께 저장할 수있다. <br> 

#### 디렉토리 경로 ('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval/data/'): 현재 탐색 중인 디렉토리의 경로입니다.
#### 서브디렉토리 목록 ([]): 현재 디렉토리 내에 있는 서브디렉토리 목록을 나타냅니다. 여기서는 빈 리스트 []로, 하위 디렉토리가 없음을 의미합니다.
#### 파일 목록 (['0409.json', '0409 (2).JSON', '0409 (1).JSON']): 현재 디렉토리에 있는 파일들의 목록입니다. 이 목록은 모든 파일을 포함하며, 파일 확장자가 대소문자 구분 없이 나열됩니다. 

<span style="background-color:skyblue;">('/home/min/llm/AI_Correct/essay_scoring_data/', ['dedup', 'qualitative_eval', '.git', 'llm_detect', 'utils', 'quantitative_eval'], ['README.md', '.gitignore'])</span>
('/home/min/llm/AI_Correct/essay_scoring_data/dedup', ['yaml'], ['load_data.py', 'run.py', 'compare.py'])
('/home/min/llm/AI_Correct/essay_scoring_data/dedup/yaml', [], ['pre_essay_data.yaml'])
('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval', ['min', 'scripts', 'image', 'src', 'docs', 'docker', 'rubric', 'deepspeed_configs', 'data', 'cicd', 'tests', 'examples', 'devtools', 'yaml'], ['train.sh', 'data_load.py', 'README.md', 'FAQS.md', 'requirements-tests.txt', 'requirements.txt', 'favicon.jpg', 'TODO.md', 'styles.css', 'requirements-dev.txt', 'index.qmd', 'setup.py', 'LICENSE', 'merge.sh', 'docker-compose.yaml', '_quarto.yml'])
('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval/min', [], ['data_load.py'])
('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval/scripts', [], ['motd', 'finetune.py', 'cloud-entrypoint.sh'])
('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval/image', [], ['axolotl.png', 'sticker_fixed.png', 'axolotl-badge-web.png'])
('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval/src', ['axolotl'], [])
('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval/src/axolotl', ['cli', 'core', 'utils', 'prompt_strategies', 'common', 'monkeypatch', 'models'], ['train.py', '__init__.py', 'loraplus.py', 'prompters.py', 'logging_config.py', 'datasets.py', 'convert.py', 'prompt_tokenizers.py'])
('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval/src/axolotl/cli', [], ['train.py', '__init__.py', 'shard.py', 'preprocess.py', 'merge_lora.py', 'inference.py'])
('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval/src/axolotl/core', ['trainers'], ['__init__.py', 'trainer_builder.py'])
('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval/src/axolotl/core/trainers', [], ['trl.py', '__init__.py'])
('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval/src/axolotl/utils', ['samplers', 'data', 'callbacks', 'config'], ['__init__.py', 'bench.py', 'schedulers.py', 'freeze.py', 'lora_embeddings.py', 'distributed.py', 'chat_templates.py', 'collators.py', 'tokenization.py', 'trainer.py', 'wandb_.py', 'models.py', 'mlflow_.py', 'dict.py'])
('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval/src/axolotl/utils/samplers', [], ['__init__.py', 'multipack.py', 'utils.py'])
('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval/src/axolotl/utils/data', [], ['__init__.py', 'sft.py', 'dpo.py', 'pretraining.py', 'utils.py'])
('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval/src/axolotl/utils/callbacks', [], ['__init__.py', 'lisa.py', 'mlflow_.py'])
('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval/src/axolotl/utils/config', ['models'], ['__init__.py'])
('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval/src/axolotl/utils/config/models', ['input', 'internals'], ['__init__.py'])
('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval/src/axolotl/utils/config/models/input', ['v0_4_1', 'next'], ['__init__.py'])
('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval/src/axolotl/utils/config/models/input/v0_4_1', [], ['__init__.py'])
('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval/src/axolotl/utils/config/models/input/next', [], ['__init__.py'])
('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval/src/axolotl/utils/config/models/internals', [], ['__init__.py'])
('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval/src/axolotl/prompt_strategies', ['dpo', 'orpo'], ['pretrain.py', '__init__.py', 'alpaca_instruct.py', 'llama2_chat.py', 'metharme.py', 'creative_acr.py', 'context_qa.py', 'pygmalion.py', 'sharegpt.py', 'input_output.py', 'orcamini.py', 'sharegpt_jokes.py', 'alpaca_w_system.py', 'alpaca_chat.py', 'completion.py', 'user_defined.py', 'base.py', 'chat_template.py', 'instruct.py'])
('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval/src/axolotl/prompt_strategies/dpo', [], ['chatml.py', '__init__.py', 'zephyr.py', 'user_defined.py'])
('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval/src/axolotl/prompt_strategies/orpo', [], ['__init__.py', 'chat_template.py'])
('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval/src/axolotl/common', [], ['__init__.py', 'const.py', 'cli.py'])
('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval/src/axolotl/monkeypatch', ['mixtral', 'data'], ['fastchat_conversation_turns.py', 'llama_expand_mask.py', 'llama_attn_hijack_xformers.py', 'multipack.py', 'relora.py', 'stablelm_attn_hijack_flash.py', 'btlm_attn_hijack_flash.py', 'llama_patch_multipack.py', 'mistral_attn_hijack_flash.py', 'llama_attn_hijack_flash.py', 'utils.py'])
('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval/src/axolotl/monkeypatch/mixtral', [], ['__init__.py'])
('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval/src/axolotl/monkeypatch/data', [], ['__init__.py', 'batch_dataset_fetcher.py'])
('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval/src/axolotl/models', ['mamba'], ['__init__.py'])
('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval/src/axolotl/models/mamba', [], ['__init__.py', 'modeling_mamba.py', 'configuration_mamba.py'])
('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval/docs', ['images', 'dataset-formats'], ['batch_vs_grad.qmd', 'input_output.qmd', 'faq.qmd', '.gitignore', 'multipack.qmd', 'rlhf.qmd', 'multi-node.qmd', 'mac.qmd', 'nccl.qmd', 'debugging.qmd', 'fsdp_qlora.qmd', 'config.qmd'])
('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval/docs/images', [], ['4d-mask.png'])
('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval/docs/dataset-formats', [], ['conversation.qmd', 'tokenized.qmd', 'template_free.qmd', 'index.qmd', 'pretraining.qmd', 'inst_tune.qmd'])
('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval/docker', [], ['Dockerfile-base', 'Dockerfile', 'Dockerfile-tests', 'Dockerfile-cloud'])
('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval/rubric', [], ['친교및정서.json', '설득.json', '정보전달.json'])
('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval/deepspeed_configs', [], ['zero3_bf16_cpuoffload_params.json', 'zero1.json', 'zero2.json', 'zero3_bf16.json', 'zero3.json', 'zero3_bf16_cpuoffload_all.json'])
('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval/data', [], ['0409.json', '0409 (2).JSON', '0409 (1).JSON'])
('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval/cicd', [], ['tests.py', 'Dockerfile.jinja', 'cicd.sh'])
('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval/tests', ['e2e', 'core', 'fixtures', 'utils', 'prompt_strategies', 'monkeypatch'], ['test_schedulers.py', 'test_datasets.py', 'test_normalize_config.py', 'test_freeze.py', 'test_data.py', 'test_prompt_tokenizers.py', 'test_expand_mask.py', 'test_tokenizers.py', 'test_packed_dataset.py', 'test_packed_pretraining.py', 'test_packed_batch_sampler.py', 'test_prompters.py', 'test_validation.py', 'test_dict.py'])
('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval/tests/e2e', ['patched'], ['test_mistral.py', '__init__.py', 'test_lora_llama.py', '.gitignore', 'test_mixtral.py', 'test_phi.py', 'test_relora_llama.py', 'test_falcon.py', 'utils.py', 'test_mamba.py', 'test_dpo.py'])
('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval/tests/e2e/patched', [], ['test_mistral_samplepack.py', 'test_resume.py', '__init__.py', 'test_phi_multipack.py', 'test_model_patches.py', 'test_fused_llama.py', 'test_lora_llama_multipack.py', 'test_falcon_samplepack.py', 'test_llama_s2_attention.py', 'test_4d_multipack_llama.py', 'test_mixtral_samplepack.py'])
('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval/tests/core', [], ['test_trainer_builder.py'])
('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval/tests/fixtures', ['alpaca'], ['conversation.tokenized.json', 'conversation.json', 'conversation.tokenized_llama2chat.json', 'conversation.missingturns.json'])
('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval/tests/fixtures/alpaca', [], ['alpaca.json'])
('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval/tests/utils', [], ['test_models.py'])
('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval/tests/prompt_strategies', [], ['test_sharegpt.py', 'test_alpaca.py', 'test_raw_io.py'])
('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval/tests/monkeypatch', [], ['test_llama_attn_hijack_flash.py'])
('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval/examples', ['jeopardy-bot', 'replit-3b', 'mamba', 'phi', 'gemma', 'qwen', 'mpt-7b', 'tiny-llama', 'pythia', 'gptj', 'openllama-3b', 'pythia-12b', 'yi-34B-chat', 'llama-2', 'xgen-7b', 'code-llama', 'mistral', 'jamba', 'stablelm-2', 'starcoder2', 'colab-notebooks', 'cerebras', 'redpajama', 'falcon'], [])
('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval/examples/jeopardy-bot', [], ['config.yml'])
('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval/examples/replit-3b', [], ['config-lora.yml'])
('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval/examples/mamba', [], ['config.yml'])
('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval/examples/phi', [], ['phi-ft.yml', 'README.md', 'phi-qlora.yml', 'phi2-ft.yml'])
('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval/examples/gemma', [], ['qlora.yml'])
('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval/examples/qwen', [], ['qwen2-moe-lora.yaml', 'qlora.yml', 'qwen2-moe-qlora.yaml', 'README.md', 'lora.yml'])
('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval/examples/mpt-7b', [], ['README.md', 'config.yml'])
('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval/examples/tiny-llama', [], ['qlora.yml', 'README.md', 'lora-mps.yml', 'lora.yml', 'pretrain.yml'])
('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval/examples/pythia', [], ['lora.yml'])
('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval/examples/gptj', [], ['qlora.yml'])
('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval/examples/openllama-3b', [], ['qlora.yml', 'README.md', 'lora.yml', 'config.yml'])
('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval/examples/pythia-12b', [], ['README.md', 'config.yml'])
('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval/examples/yi-34B-chat', [], ['qlora.yml', 'README.md'])
('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval/examples/llama-2', [], ['fft_optimized.yml', 'qlora.yml', 'qlora-fsdp.yml', 'README.md', 'gptq-lora.yml', 'lora.yml', 'lisa.yml', 'relora.yml', 'loftq.yml'])
('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval/examples/xgen-7b', [], ['xgen-7b-8k-qlora.yml'])
('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval/examples/code-llama', ['7b', '13b', '34b'], ['README.md'])
('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval/examples/code-llama/7b', [], ['qlora.yml', 'lora.yml'])
('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval/examples/code-llama/13b', [], ['qlora.yml', 'lora.yml'])
('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval/examples/code-llama/34b', [], ['qlora.yml', 'lora.yml'])
('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval/examples/mistral', [], ['qlora.yml', 'README.md', 'mixtral.yml', 'lora-mps.yml', 'lora.yml', 'config.yml', 'mixtral-qlora-fsdp.yml'])
('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval/examples/jamba', [], ['README.md', 'qlora.yaml', 'qlora_deepspeed.yaml'])
('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval/examples/stablelm-2', ['1.6b'], ['README.md'])
('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval/examples/stablelm-2/1.6b', [], ['fft.yml', 'lora.yml'])
('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval/examples/starcoder2', [], ['qlora.yml'])
('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval/examples/colab-notebooks', [], ['colab-axolotl-example.ipynb'])
('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval/examples/cerebras', [], ['qlora.yml', 'btlm-ft.yml'])
('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval/examples/redpajama', [], ['README.md', 'config-3b.yml'])
('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval/examples/falcon', [], ['config-7b-lora.yml', 'config-7b-qlora.yml', 'config-7b.yml'])
('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval/devtools', [], ['README.md', 'dev_sharegpt.yml'])
('/home/min/llm/AI_Correct/essay_scoring_data/qualitative_eval/yaml', [], ['qulitative_eval.yaml'])
('/home/min/llm/AI_Correct/essay_scoring_data/.git', ['branches', 'logs', 'info', 'refs', 'hooks', 'objects'], ['index', 'HEAD', 'description', 'packed-refs', 'config'])
('/home/min/llm/AI_Correct/essay_scoring_data/.git/branches', [], [])
('/home/min/llm/AI_Correct/essay_scoring_data/.git/logs', ['refs'], ['HEAD'])
('/home/min/llm/AI_Correct/essay_scoring_data/.git/logs/refs', ['heads', 'remotes'], [])
('/home/min/llm/AI_Correct/essay_scoring_data/.git/logs/refs/heads', [], ['main'])
('/home/min/llm/AI_Correct/essay_scoring_data/.git/logs/refs/remotes', ['origin'], [])
('/home/min/llm/AI_Correct/essay_scoring_data/.git/logs/refs/remotes/origin', [], ['HEAD'])
('/home/min/llm/AI_Correct/essay_scoring_data/.git/info', [], ['exclude'])
('/home/min/llm/AI_Correct/essay_scoring_data/.git/refs', ['heads', 'remotes', 'tags'], [])
('/home/min/llm/AI_Correct/essay_scoring_data/.git/refs/heads', [], ['main'])
('/home/min/llm/AI_Correct/essay_scoring_data/.git/refs/remotes', ['origin'], [])
('/home/min/llm/AI_Correct/essay_scoring_data/.git/refs/remotes/origin', [], ['HEAD'])
('/home/min/llm/AI_Correct/essay_scoring_data/.git/refs/tags', [], [])
('/home/min/llm/AI_Correct/essay_scoring_data/.git/hooks', [], ['pre-commit.sample', 'fsmonitor-watchman.sample', 'pre-rebase.sample', 'pre-push.sample', 'post-update.sample', 'update.sample', 'prepare-commit-msg.sample', 'pre-applypatch.sample', 'commit-msg.sample', 'applypatch-msg.sample', 'pre-merge-commit.sample', 'pre-receive.sample'])
('/home/min/llm/AI_Correct/essay_scoring_data/.git/objects', ['pack', 'info'], [])
('/home/min/llm/AI_Correct/essay_scoring_data/.git/objects/pack', [], ['pack-13acc36f48491b439e927fbfee22a12e7963dbf7.idx', 'pack-13acc36f48491b439e927fbfee22a12e7963dbf7.pack'])
('/home/min/llm/AI_Correct/essay_scoring_data/.git/objects/info', [], [])
<span style="background-color: skyblue">('/home/min/llm/AI_Correct/essay_scoring_data/llm_detect', ['train', 'inference', 'model', 'data'], [])</span>
('/home/min/llm/AI_Correct/essay_scoring_data/llm_detect/train', ['__pycache__', 'yaml'], ['dataset.py', 'trainer.py', 'model.py', 'run.py', 'read.py'])
('/home/min/llm/AI_Correct/essay_scoring_data/llm_detect/train/__pycache__', [], ['dataset.cpython-38.pyc', 'model.cpython-38.pyc', 'trainer.cpython-38.pyc'])
('/home/min/llm/AI_Correct/essay_scoring_data/llm_detect/train/yaml', [], ['train.yaml'])
('/home/min/llm/AI_Correct/essay_scoring_data/llm_detect/inference', [], ['inference.py'])
('/home/min/llm/AI_Correct/essay_scoring_data/llm_detect/model', [], [])
('/home/min/llm/AI_Correct/essay_scoring_data/llm_detect/data', [], ['detect_llm.csv'])
('/home/min/llm/AI_Correct/essay_scoring_data/utils', [], ['yaml_load.py'])
('/home/min/llm/AI_Correct/essay_scoring_data/quantitative_eval', ['yaml'], ['run.py'])
('/home/min/llm/AI_Correct/essay_scoring_data/quantitative_eval/yaml', [], ['quantitative_eval.yaml'])



